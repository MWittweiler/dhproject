{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49eb33d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the poetic texts: Orthographic variants, Verses should be condensed to sentences\n",
    "# Code mostly reused from ....\n",
    "\n",
    "from typing import Dict, List\n",
    "import re\n",
    "import csv\n",
    "\n",
    "# Initialize text\n",
    "def load_text(filename: str) -> list:\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        text_list = file.readlines()\n",
    "        text = []\n",
    "        for line in text_list:\n",
    "            line = line.split(\"\\t\")\n",
    "            text.append(line)\n",
    "    return text\n",
    "\n",
    "def tokenizer(text: str) -> list:\n",
    "    \"\"\"\n",
    "    Tokenizes the given text by splitting it into words based on specified delimiters.\n",
    "    \n",
    "    Parameters:\n",
    "        text (str): The text to tokenize.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of words extracted from the text.\n",
    "    \"\"\"\n",
    "    # Include punctuation marks as separate tokens\n",
    "    tokens = re.findall(r'\\w+|[^\\w\\s]', text, re.UNICODE)\n",
    "    return tokens\n",
    "\n",
    "def read_in_text(input_text: str) -> List[List[str]]:\n",
    "    \"\"\"\n",
    "    Reads the input text file and returns its content as a list of rows.\n",
    "    \n",
    "    Parameters:\n",
    "        input_text (str): Path to the input text file.\n",
    "    \n",
    "    Returns:\n",
    "        List[List[str]]: A list containing the rows of the input file.\n",
    "    \"\"\"\n",
    "    with open(input_text, \"r\", newline='', encoding='utf-8') as samplefile: \n",
    "        reader = csv.reader(samplefile, delimiter=\"\\t\", quoting=csv.QUOTE_NONE) \n",
    "        my_list = list(reader)\n",
    "    return my_list\n",
    "\n",
    "def transform_token(token: str)-> str:\n",
    "    \"\"\"\n",
    "    Transforms a token based on predefined prefix rules.\n",
    "    \n",
    "    Parameters:\n",
    "        token (str): The token to transform.\n",
    "    \n",
    "    Returns:\n",
    "        str: The transformed token.\n",
    "    \"\"\"\n",
    "    # Dictionary mapping prefixes to their transformations\n",
    "    prefix_map = {\n",
    "    'adt': 'att', 'Adt': 'Att', 'adp': 'app', 'Adp': 'App', 'adc': 'acc', 'Adc': 'Acc',\n",
    "    'adg': 'agg', 'Adg': 'Agg', 'adf': 'aff', 'Adf': 'Aff', 'adl': 'all', 'Adl': 'All',\n",
    "    'adr': 'arr', 'Adr': 'Arr', 'ads': 'ass', 'Ads': 'Ass', 'adqu': 'acqu', 'Adqu': 'Acqu',\n",
    "    'inm': 'imm', 'Inm': 'Imm', 'inl': 'ill', 'Inl': 'Ill', 'inr': 'irr', 'Inr': 'Irr',\n",
    "    'inb': 'imb', 'Inb': 'Imb', 'conm': 'comm', 'Conm': 'Comm', 'conl': 'coll', 'Conl': 'Coll',\n",
    "    'conr': 'corr', 'Conr': 'Corr', 'conb': 'comb', 'Conb': 'Comb', 'conp': 'comp', 'Conp': 'Comp'}\n",
    "    vowels = 'aeiou'\n",
    "    # Determine if the token starts with a recognized prefix\n",
    "    for prefix, replacement in prefix_map.items():\n",
    "        if token.lower().startswith(prefix):\n",
    "            # Special handling for 'ads'/'Ads'\n",
    "            if prefix.lower() == 'ads' and len(token) > 3:\n",
    "                if token[3].lower() in vowels:\n",
    "                    # Only apply replacement if followed by a vowel\n",
    "                    new_start = token[0] + replacement[1:]  # Assimilate (eg. adserit > asserit)\n",
    "                    return new_start + token[3:]\n",
    "                else:\n",
    "                    new_start = token[0] + token[2:] # Keep simple consonant before consonant (eg. adstringit > astringit)\n",
    "                    return new_start\n",
    "            elif prefix.lower() != 'ads':  # Apply other transformations directly\n",
    "                new_start = token[0] + replacement[1:]  # Maintain case of the first letter\n",
    "                return new_start + token[len(prefix):]\n",
    "            break  # Exit the loop after finding the first matching prefix\n",
    "    return token  # Return the token unchanged if no prefix matches\n",
    "\n",
    "def assimilate(my_list: List[List[str]]) -> List[List[str]]:\n",
    "    \"\"\"\n",
    "    Applies assimilation rules to each sentence in the list.\n",
    "    \n",
    "    Parameters:\n",
    "        my_list (List[List[str]]): A list of sentences to process.\n",
    "    \n",
    "    Returns:\n",
    "        List[List[str]]: The list with assimilated sentences.\n",
    "    \"\"\"\n",
    "    for text in my_list:\n",
    "        tokens = tokenizer(text[1])  # Tokenize the text\n",
    "        for i, token in enumerate(tokens):\n",
    "            transformed_token = transform_token(token)\n",
    "            if transformed_token:\n",
    "                neu = text[1].replace(tokens[i],transformed_token)\n",
    "                text[1] = neu \n",
    "    return my_list\n",
    "\n",
    "def normalize_quotation_marks(text_list: List[List[str]]) -> List[List[str]]:\n",
    "    \"\"\"\n",
    "    Replace all types of quotation marks in each text string with a standard apostrophe.\n",
    "\n",
    "    Args:\n",
    "    - text_list: A list of lists, where each inner list contains an ID and a text string.\n",
    "\n",
    "    Returns:\n",
    "    - A new list of lists with quotation marks normalized in the text strings.\n",
    "    \"\"\"\n",
    "    new_text_list = [[sublist[0], re.sub(\"[\\\"”“„’‘]\", \"\\'\", sublist[1])] for sublist in text_list]\n",
    "    return new_text_list\n",
    "\n",
    "# Connect -que and -ve with their preceding words\n",
    "def remove_whitespace_before_connectors(text_list: List[List[str]]) -> List[List[str]]:\n",
    "    \"\"\"\n",
    "    Remove whitespace before '-que' and '-ve' in each text string.\n",
    "\n",
    "    Args:\n",
    "    - text_list: A list of lists, where each inner list contains an ID and a text string.\n",
    "\n",
    "    Returns:\n",
    "    - A new list of lists with the whitespace removed before connectors in the text strings.\n",
    "    \"\"\"\n",
    "    new_text_list = [[sublist[0], re.sub(\" (que|ve|ue)([ ,\\.!?])\", r\"\\1\\2\", sublist[1])] for sublist in text_list]\n",
    "    return new_text_list\n",
    "\n",
    "# Remove digits (left over chapter numbers) at the start of each unit\n",
    "def remove_left_over_counts(text_list: List[List[str]]) -> List[List[str]]:\n",
    "    \"\"\"\n",
    "    Remove digits (leftover chapter numbers) at the start of each text string.\n",
    "\n",
    "    Args:\n",
    "    - text_list: A list of lists, where each inner list contains an ID and a text string.\n",
    "\n",
    "    Returns:\n",
    "    - A new list of lists with the leading digits removed from the text strings.\n",
    "    \"\"\"\n",
    "    new_text_list = [[sublist[0], re.sub('\\A\\d{1,3}\\.?', \"\", sublist[1])] for sublist in text_list]\n",
    "    return new_text_list\n",
    "    \n",
    "def strip_whitespaces(text_list: List[List[str]]) -> List[List[str]]:\n",
    "    \"\"\"\n",
    "    Remove leading and trailing whitespaces from the text strings in each sublist.\n",
    "\n",
    "    Args:\n",
    "        text_list: A list of sublists, each containing an ID and a text string.\n",
    "\n",
    "    Returns:\n",
    "        A new list of sublists with leading and trailing whitespaces removed from the text strings.\n",
    "    \"\"\"\n",
    "    new_text_list = [[sublist[0], sublist[1].strip()] for sublist in text_list]\n",
    "    return new_text_list\n",
    "\n",
    "def separate_text_at_ellipsis(text_list: List[List[str]]) -> List[List[str]]:\n",
    "    \"\"\"\n",
    "    Separate text at ellipsis ('...') points, creating new sublists for text following the ellipsis. If an ellipsis is followed by an apostrophe (\"...'\"), it includes the apostrophe in the separation.\n",
    "\n",
    "    Args:\n",
    "        text_list: A list of sublists, each containing an ID and a text string.\n",
    "\n",
    "    Returns:\n",
    "        The modified list with additional sublists created for text following ellipsis points.\n",
    "    \"\"\"\n",
    "    k = 0\n",
    "    while k < len(text_list):\n",
    "        sublist = text_list[k]\n",
    "        if '...' in sublist[1]:\n",
    "            i1 = sublist[1].index('...')\n",
    "            if sublist[1][i1:i1+4] == \"...\\'\":\n",
    "                text_list.insert(k+1, [sublist[0], sublist[1][i1+4:]])\n",
    "                sublist[1] = sublist[1][:i1+4]\n",
    "            else:\n",
    "                text_list.insert(k+1, [sublist[0], sublist[1][i1+3:]])\n",
    "                sublist[1] = sublist[1][:i1+3]\n",
    "        k = k+1\n",
    "    return text_list\n",
    "\n",
    "def separate_text_at_punctuation_marks(text_list: List[List[str]]) -> List[List[str]]:\n",
    "    \"\"\"\n",
    "    Separate text at specific punctuation marks (., ?, !, and : '), creating new sublists for text following these marks. This function takes care to not split ellipsis ('...').\n",
    "\n",
    "    Args:\n",
    "        text_list: A list of sublists, each containing an ID and a text string.\n",
    "\n",
    "    Returns:\n",
    "        The modified list with additional sublists created for text following the specified punctuation marks.\n",
    "    \"\"\"\n",
    "    k = 0\n",
    "    while k < len(text_list):\n",
    "        sublist = text_list[k]\n",
    "        if '.' in sublist[1] or '?' in sublist[1] or '!' in sublist[1] or ': \\'' in sublist[1]:\n",
    "            if '.' in sublist[1]:\n",
    "                i1 = sublist[1].index('.')\n",
    "                if sublist[1][i1:i1+3] == '...': # Make sure elipsis does not get split\n",
    "                    i1= len(sublist[1])+2\n",
    "            else:\n",
    "                i1 = len(sublist[1])+2\n",
    "            if '?' in sublist[1]:\n",
    "                i2 = sublist[1].index('?')\n",
    "            else:\n",
    "                i2 = len(sublist[1])+2\n",
    "            if '!' in sublist[1]:\n",
    "                i3 = sublist[1].index('!')\n",
    "            else:\n",
    "                i3 = len(sublist[1])+2\n",
    "            if ': \\'' in sublist[1]:\n",
    "                i4 = sublist[1].index(': \\'')\n",
    "            else:\n",
    "                i4 = len(sublist[1])+2\n",
    "            l = min(i1, i2, i3, i4)\n",
    "            text_list.insert(k+1, [sublist[0], sublist[1][l+2:]])\n",
    "            sublist[1] = sublist[1][:l+2]\n",
    "        k = k+1\n",
    "    return text_list\n",
    "\n",
    "def cleanup(input_list: List[List[str]]) -> List[List[str]]:\n",
    "    \"\"\"\n",
    "    Remove sublists with empty or whitespace-only text strings, and strip leading and trailing whitespaces from remaining text strings.\n",
    "\n",
    "    Args:\n",
    "        input_list: A list of sublists, each containing an ID and a text string.\n",
    "\n",
    "    Returns:\n",
    "        A cleaned list of sublists with whitespaces stripped and empty or whitespace-only text strings removed.\n",
    "    \"\"\"\n",
    "    output_list = [[sublist[0], sublist[1].strip()] for sublist in input_list if len(sublist) > 0 and len(sublist[1]) > 1]\n",
    "    return output_list\n",
    "\n",
    "def apply_condition_and_action(text_list: List[List[str]], condition_func: callable, action_func: callable) -> List[List[str]]:\n",
    "    \"\"\"\n",
    "    Apply a condition and action to each pair of consecutive sublists in the text list.\n",
    "\n",
    "    Args:\n",
    "    - text_list: A list of lists, each containing an ID and a text string.\n",
    "    - condition_func: A function that takes two sublists and returns True if the action should be applied.\n",
    "    - action_func: A function that applies a transformation based on the condition, modifying the text list in place.\n",
    "\n",
    "    Returns:\n",
    "    - The modified text list after applying the condition and action functions.\n",
    "    \"\"\"\n",
    "    k = 0\n",
    "    while k < len(text_list)-1:  # Adjust to prevent index out of range for operations involving the next element\n",
    "        if condition_func(text_list[k], text_list[k+1]):\n",
    "            action_func(k, text_list)\n",
    "        k += 1\n",
    "    return text_list\n",
    "\n",
    "def mark_verse_endings(text_list: List[List[str]]) -> List[List[str]]:\n",
    "    \"\"\"\n",
    "    Append a marker (' /') at the end of each text string in the list to denote verse endings.\n",
    "\n",
    "    Args:\n",
    "        text_list: A list of sublists, each containing an ID and a text string representing a verse.\n",
    "\n",
    "    Returns:\n",
    "        A new list of sublists where each text string is appended with ' /' to denote the end of a verse.\n",
    "    \"\"\"\n",
    "    new_text_list = [[sublist[0], sublist[1] + ' /'] for sublist in text_list]\n",
    "    return new_text_list\n",
    "\n",
    "def remove_left_over_marks(text_list: List[List[str]]) -> List[List[str]]:\n",
    "    \"\"\"\n",
    "    Remove left over marks ('/ ') from the beginning of each text string in the list.\n",
    "\n",
    "    Args:\n",
    "        text_list: A list of sublists, each containing an ID and a text string.\n",
    "\n",
    "    Returns:\n",
    "        A new list of sublists where each text string starting with '/ ' has had those initial characters removed.\n",
    "    \"\"\"\n",
    "    new_text_list = [[sublist[0], sublist[1][2:] if sublist[1][:2] == '/ ' else sublist[1]] for sublist in text_list ]\n",
    "    return new_text_list\n",
    "\n",
    "def condition_contract_verse_endings(sublist: List[str], next_sublist: List[str]) -> bool:\n",
    "    \"\"\"\n",
    "    Determine if the ending of a verse (' /') should lead to a contraction with the subsequent verse, excluding cases where the marker is part of a specific pattern (': /').\n",
    "\n",
    "    Args:\n",
    "        sublist: The current sublist containing an ID and a text string representing a verse.\n",
    "        next_sublist: The subsequent sublist containing an ID and a text string representing the next verse.\n",
    "\n",
    "    Returns:\n",
    "        A boolean value: True if the current verse ends with ' /' (excluding ': /') and should be contracted with the next, False otherwise.\n",
    "    \"\"\"\n",
    "    return sublist[1][-2:] == ' /' and not sublist[1][-3:] == ': /'\n",
    "\n",
    "def condition_insertions_in_brackets(sublist: List[str], next_sublist: List[str]) -> bool:\n",
    "    \"\"\"\n",
    "    Check if a text contains an opening bracket '(' without a corresponding closing bracket ')' afterwards. This function is used to identify cases where text spans multiple sublists due to an unclosed bracket.\n",
    "\n",
    "    Args:\n",
    "    - sublist: A list containing an ID and a text string, where the condition is checked.\n",
    "    - next_sublist: The subsequent list containing an ID and a text string, not directly used in this condition but included for consistency with the framework.\n",
    "\n",
    "    Returns:\n",
    "    - A boolean value: True if there's an opening bracket without a closing bracket, False otherwise.\n",
    "    \"\"\"\n",
    "    return '(' in sublist[1] and ')' not in sublist[1][sublist[1].index('('):]\n",
    "\n",
    "def condition_after_interjections(sublist: List[str], next_sublist: List[str]) -> bool:\n",
    "    \"\"\"\n",
    "    Check if the end of the current text string contains specific interjection patterns (' a!' or ' o!').\n",
    "\n",
    "    Args:\n",
    "        sublist: The current sublist containing an ID and a text string.\n",
    "        next_sublist: The subsequent sublist. This parameter is included for consistency but not used in this condition.\n",
    "\n",
    "    Returns:\n",
    "        A boolean indicating whether the current text string ends with a specified interjection pattern.\n",
    "    \"\"\"\n",
    "    return sublist[1][-3:] in [' a!', ' o!']\n",
    "\n",
    "def condition_contract_insertions(sublist: List[str], next_sublist: List[str]) -> bool:\n",
    "    \"\"\"\n",
    "    Determine if the start of the next text string contains a specific insertion pattern ('—').\n",
    "\n",
    "    Args:\n",
    "        sublist: The current sublist containing an ID and a text string.\n",
    "        next_sublist: The subsequent sublist containing an identifier and a text string to check for the insertion pattern.\n",
    "\n",
    "    Returns:\n",
    "        A boolean indicating whether the next text string starts with the specified insertion pattern.\n",
    "    \"\"\"\n",
    "    return next_sublist[1][0] == '—'\n",
    "\n",
    "def condition_direct_speeches_1(sublist: List[str], next_sublist: List[str]) -> bool:\n",
    "    \"\"\"\n",
    "    Check for a pattern indicating the beginning of inserted direct speeches, where the current text string ends with an apostrophe and the next text string starts with certain Latin terms ('inquit', 'ait', 'dixit', 'dicit').\n",
    "\n",
    "    Args:\n",
    "        sublist: The current sublist containing an ID and a text string ending with an apostrophe.\n",
    "        next_sublist: The subsequent sublist containing an ID and a text string starting with the specified Latin term.\n",
    "\n",
    "    Returns:\n",
    "        A boolean indicating the presence of a direct speech pattern across the current and next text strings.\n",
    "    \"\"\"\n",
    "    return sublist[1][-1] == '\\'' and (\n",
    "        next_sublist[1].startswith('inquit') or \n",
    "        next_sublist[1].startswith('ait') or \n",
    "        next_sublist[1].startswith('dixit') or \n",
    "        next_sublist[1].startswith('dicit')\n",
    "    )\n",
    "\n",
    "def condition_direct_speeches_2(sublist: List[str], next_sublist: List[str]) -> bool:\n",
    "    \"\"\"\n",
    "    Check for a pattern indicating the beginning of inserted direct speeches, similar to 'condition_direct_speeches_1', but for cases where the next text string starts with a comma followed by certain Latin terms (', inquit', ', ait', ', dixit', ', dicit').\n",
    "\n",
    "    Args:\n",
    "        sublist: The current sublist containing an ID and a text string ending with an apostrophe.\n",
    "        next_sublist: The subsequent sublist containing an ID and a text string starting with a comma followed by a Latin term.\n",
    "\n",
    "    Returns:\n",
    "        A boolean indicating the presence of a direct speech pattern with a preceding comma across the current and next text strings.\n",
    "    \"\"\"\n",
    "    return sublist[1][-1] == '\\'' and (\n",
    "        next_sublist[1].startswith(', inquit') or \n",
    "        next_sublist[1].startswith(', ait') or \n",
    "        next_sublist[1].startswith(', dixit') or \n",
    "        next_sublist[1].startswith(', dicit')\n",
    "    )\n",
    "\n",
    "def action_contract_next(k: int, text_list: List[List[str]]) -> None:\n",
    "    \"\"\"\n",
    "    Concatenates the text of the next sublist to the current sublist with a space in between and then clears the text of the current sublist.\n",
    "\n",
    "    Args:\n",
    "        k: The index of the current sublist in the text_list.\n",
    "        text_list: A list of sublists, each containing an ID and a text string.\n",
    "\n",
    "    Returns:\n",
    "        None. The function modifies the list in place.\n",
    "    \"\"\"\n",
    "    text_list[k+1] = [text_list[k][0], text_list[k][1] + ' ' + text_list[k+1][1]]\n",
    "    text_list[k][1] = ''\n",
    "\n",
    "def contract_after_personal_names(text_list: List[List[str]]) -> List[List[str]]:\n",
    "    \"\"\"\n",
    "    Contracts text after personal names, dates, and common abbreviations by appending the text of the next sublist to the current one if the current sublist ends with specific patterns.\n",
    "\n",
    "    Args:\n",
    "        text_list: A list of sublists, each containing an identifier and a text string.\n",
    "\n",
    "    Returns:\n",
    "        The modified text list after the contraction process.\n",
    "    \"\"\"\n",
    "    l = 0\n",
    "    while l < len(text_list):\n",
    "        sublist = text_list[l]\n",
    "        if sublist[1][-2:] == 'A.' or sublist[1][-3:] == ' a.' or sublist[1][-3:] == ' b.' or sublist[1][-2:] == 'C.' or sublist[1][-3:] == ' c.' or sublist[1][-2:] == 'D.' or sublist[1][-3:] == ' d.' or sublist[1][-2:] == 'E.' or sublist[1][-3:] == ' e.' or sublist[1][-3:] == ' f.' or sublist[1][-2:] == 'H.' or sublist[1][-2:] == 'L.' or sublist[1][-2:] == 'M.' or sublist[1][-3:] == ' m.' or sublist[1][-2:] == 'N.' or sublist[1][-2:] == 'P.' or sublist[1][-3:] == ' p.' or sublist[1][-2:] == 'Q.' or sublist[1][-3:] == ' q.' or sublist[1][-2:] == 'S.' or sublist[1][-2:] == 'T.' or sublist[1][-3:] == ' t.' or sublist[1][-3:] == ' v.' or sublist[1][-3:] == 'An.' or sublist[1][-4:] == ' an.' or sublist[1][-3:] == 'Cn.' or sublist[1][-4:] == ' in.' or sublist[1][-4:] == ' ex.'or sublist[1][-4:] == ' ut.' or sublist[1][-3:] == 'M\\'.' or sublist[1][-3:] == 'R\\'.' or sublist[1][-4:] == ' pl.' or sublist[1][-3:] == 'Sp.' or sublist[1][-3:] == 'Ti.' or sublist[1][-4:] == ' tr.' or sublist[1][-3:] == 'Id.' or sublist[1][-4:] == 'App.' or sublist[1][-4:] == 'Ser.' or sublist[1][-4:] == 'Sex.' or sublist[1][-4:] == 'Tib.' or sublist[1][-5:] == ' cos.' or sublist[1][-4:] == 'Cos.' or sublist[1][-4:] == 'Kal.' or sublist[1][-5:] == ' kal.' or sublist[1][-5:] == ' med.' or sublist[1][-4:] == 'Med.' or sublist[1][-4:] == 'Non.' or sublist[1][-5:] == ' non.' or sublist[1][-5:] == ' scr.' or sublist[1][-4:] == 'Scr.' or sublist[1][-5:] == ' vid.' or sublist[1][-4:] == 'Vid.' or sublist[1][-5:] == 'Mart.' or sublist[1][-4:] == 'Apr.' or sublist[1][-4:] == 'Mai.' or sublist[1][-4:] == 'Iun.' or sublist[1][-6:] == 'Quint.' or sublist[1][-5:] == 'Sext.' or sublist[1][-5:] == 'Sept.' or sublist[1][-4:] == 'Oct.' or sublist[1][-4:] == 'Nov.' or sublist[1][-4:] == 'Dec.' or sublist[1][-4:] == 'Ian.' or sublist[1][-5:] == 'Febr.' or sublist[1][-6:] == ' coss.' or sublist[1][-5:] == 'Coss.' or sublist[1][-5:] == 'fort.' or sublist[1][-6:] == ' prid.' or sublist[1][-5:] == 'Prid.' or sublist[1][-2:] == '.,' or sublist[1][-2:] == '?)' or sublist[1][-4:] == 'frg.' or sublist[1][-6:] == 'Schol.' or sublist[1][-4:] == 'Cus.': \n",
    "            text_list[l+1] = [sublist[0], sublist[1] + ' ' + text_list[l+1][1]]\n",
    "            sublist.clear()    \n",
    "        l = l+1\n",
    "    return text_list\n",
    "\n",
    "def write_output(text_list: List[List[str]], output_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Writes the content of text_list to a txt file at the specified output path.\n",
    "\n",
    "    Args:\n",
    "        text_list: A list of sublists, each containing an identifier and a text string.\n",
    "        output_path: The file path where the output txt file will be written.\n",
    "    \"\"\"\n",
    "    with open(output_path, 'w', newline='', encoding='utf-8') as file:\n",
    "        result = csv.writer(file, delimiter='\\t', quotechar='|')\n",
    "        for i in text_list:\n",
    "            if len(i) > 1:\n",
    "                result.writerow(i)\n",
    "\n",
    "def assimilation(input_text: str, output_path: str) -> List[List[str]]:\n",
    "    \"\"\"\n",
    "    Processes the input text through assimilation steps.\n",
    "\n",
    "    Args:\n",
    "        input_text: The path to the input text file to be assimilated.\n",
    "        output_path: The file path where the assimilated text will be written.\n",
    "\n",
    "    Returns:\n",
    "        A list of sublists, each containing an ID and the assimilated text string.\n",
    "    \"\"\"\n",
    "    text_list = read_in_text(input_text)\n",
    "    assimilated_list = assimilate(text_list)\n",
    "    return assimilated_list\n",
    "\n",
    "def phrasing_prose(text_list: List[List[str]], output_path: str) -> List[List[str]]:\n",
    "    \"\"\"\n",
    "    Processes a list of text elements for prose by applying a series of normalization and cleanup steps, including normalization of quotation marks, removal of whitespace\n",
    "    around connectors, stripping of leading chapter numbers and whitespace, and separation of text at ellipsis and punctuation marks. Conditions and actions are applied to handle\n",
    "    specific formatting cases.\n",
    "\n",
    "    Args:\n",
    "        text_list: A list of sublists, each containing an ID and a text string.\n",
    "        output_path: The file path where the processed text will be written.\n",
    "\n",
    "    Returns:\n",
    "        The processed list of text elements after applying all normalization and cleanup steps.\n",
    "    \"\"\"\n",
    "    text_list = normalize_quotation_marks(text_list)\n",
    "    text_list = remove_whitespace_before_connectors(text_list)\n",
    "    text_list = remove_left_over_counts(text_list)\n",
    "    text_list = strip_whitespaces(text_list)\n",
    "    text_list = separate_text_at_ellipsis(text_list)\n",
    "    text_list = separate_text_at_punctuation_marks(text_list)\n",
    "    text_list = cleanup(text_list)\n",
    "    text_list = apply_condition_and_action(text_list, condition_insertions_in_brackets, action_contract_next)\n",
    "    text_list = cleanup(text_list)\n",
    "    text_list = apply_condition_and_action(text_list, condition_after_interjections, action_contract_next)\n",
    "    text_list = cleanup(text_list)\n",
    "    text_list = apply_condition_and_action(text_list, condition_contract_insertions, action_contract_next)\n",
    "    text_list = cleanup(text_list)\n",
    "    text_list = apply_condition_and_action(text_list, condition_direct_speeches_1, action_contract_next)\n",
    "    text_list = cleanup(text_list)\n",
    "    text_list = apply_condition_and_action(text_list, condition_direct_speeches_2, action_contract_next)\n",
    "    text_list = cleanup(text_list)\n",
    "    text_list = contract_after_personal_names(text_list)\n",
    "    text_list = cleanup(text_list)\n",
    "    write_output(text_list, output_path)\n",
    "    return text_list\n",
    "\n",
    "def phrasing_poetry(text_list: List[List[str]], output_path: str) -> List[List[str]]:\n",
    "    \"\"\"\n",
    "    Processes a list of text elements for poetry by marking verse endings, applying a series of normalization and cleanup steps similar to prose, but with additional handling for verse\n",
    "    endings.\n",
    "\n",
    "    Args:\n",
    "        text_list: A list of sublists, each containing an ID and a text string.\n",
    "        output_path: The file path where the processed poetry text will be written.\n",
    "\n",
    "    Returns:\n",
    "        The processed list of poetry text elements after applying all normalization, cleanup,\n",
    "        and verse ending marking steps.\n",
    "    \"\"\"\n",
    "    text_list = mark_verse_endings(text_list)\n",
    "    text_list = normalize_quotation_marks(text_list)\n",
    "    text_list = remove_whitespace_before_connectors(text_list)\n",
    "    text_list = remove_left_over_counts(text_list)\n",
    "    text_list = strip_whitespaces(text_list)\n",
    "    text_list = separate_text_at_ellipsis(text_list)\n",
    "    text_list = separate_text_at_punctuation_marks(text_list)\n",
    "    text_list = apply_condition_and_action(text_list, condition_contract_verse_endings, action_contract_next)\n",
    "    text_list = cleanup(text_list)\n",
    "    text_list = apply_condition_and_action(text_list, condition_insertions_in_brackets, action_contract_next)\n",
    "    text_list = cleanup(text_list)\n",
    "    text_list = apply_condition_and_action(text_list, condition_after_interjections, action_contract_next)\n",
    "    text_list = cleanup(text_list)\n",
    "    text_list = apply_condition_and_action(text_list, condition_contract_insertions, action_contract_next)\n",
    "    text_list = cleanup(text_list)\n",
    "    text_list = apply_condition_and_action(text_list, condition_direct_speeches_1, action_contract_next)\n",
    "    text_list = cleanup(text_list)\n",
    "    text_list = apply_condition_and_action(text_list, condition_direct_speeches_2, action_contract_next)\n",
    "    text_list = cleanup(text_list)\n",
    "    text_list = contract_after_personal_names(text_list)\n",
    "    text_list = cleanup(text_list)\n",
    "    text_list = remove_left_over_marks(text_list)\n",
    "    write_output(text_list, output_path)\n",
    "    return text_list\n",
    "\n",
    "works = [\"aeneid\", \"pharsalia\", \"thebaid\", \"argonautica\", \"punica\"]\n",
    "for work in works:\n",
    "    text = read_in_text(f\"../texts/{work}.txt\")\n",
    "    cleaned_text = phrasing_poetry(text, output_path=f\"../texts/{work}_clean.txt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dhprojectlap",
   "language": "python",
   "name": "dhprojectlap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
